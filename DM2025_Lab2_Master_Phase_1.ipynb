{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nattapat140/DM2025-Lab1-Exercise/blob/main/DM2025_Lab2_Master_Phase_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Colab Environment Setup**"
      ],
      "metadata": {
        "id": "Qw2by_FRupg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Importing our Google News Data\n",
        "google_news_vectors_path = kagglehub.dataset_download('didiersalazar/google-news-vectors')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YWogxXfuoIY",
        "outputId": "ff927cb8-3929-43ab-dd5a-d09716cc87e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'google-news-vectors' dataset.\n",
            "Data source import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_news_vectors_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CzUNZhN6utM3",
        "outputId": "cae922b4-a979-42fd-c586-a5d40e52096c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/google-news-vectors'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone Lab 2's github repository to get all of our material first\n",
        "\n",
        "!git clone https://github.com/difersalest/DM2025-Lab2-Exercise.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKZzK88Tuu4U",
        "outputId": "b52d3ef6-ae77-4633-ba7f-b5ffa1988023"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DM2025-Lab2-Exercise' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing all of our dependencies\n",
        "# The lab in colab was tested with this, and everything should work as intended\n",
        "# If in your case something is not working please notify the TAs\n",
        "!pip3 install python-dotenv==1.1.1 gensim==4.3.3 tensorflow==2.20.0 tensorflow-hub==0.16.1 keras==3.11.3 jupyter==1.1.1 scikit-learn==1.7.1 pandas==2.3.2 numpy==1.26.4 matplotlib==3.10.6 plotly==6.3.0 seaborn==0.13.2 nltk==3.9.1 umap-learn==0.5.9.post2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrrPPbKeu_GH",
        "outputId": "cc947aad-2498-48d5-9dea-f35994730997"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv==1.1.1 in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: gensim==4.3.3 in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: tensorflow==2.20.0 in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.16.1 in /usr/local/lib/python3.12/dist-packages (0.16.1)\n",
            "Requirement already satisfied: keras==3.11.3 in /usr/local/lib/python3.12/dist-packages (3.11.3)\n",
            "Requirement already satisfied: jupyter==1.1.1 in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: scikit-learn==1.7.1 in /usr/local/lib/python3.12/dist-packages (1.7.1)\n",
            "Requirement already satisfied: pandas==2.3.2 in /usr/local/lib/python3.12/dist-packages (2.3.2)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib==3.10.6 in /usr/local/lib/python3.12/dist-packages (3.10.6)\n",
            "Requirement already satisfied: plotly==6.3.0 in /usr/local/lib/python3.12/dist-packages (6.3.0)\n",
            "Requirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: umap-learn==0.5.9.post2 in /usr/local/lib/python3.12/dist-packages (0.5.9.post2)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim==4.3.3) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim==4.3.3) (7.4.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (2.20.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (0.5.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-hub==0.16.1) (2.20.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras==3.11.3) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras==3.11.3) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras==3.11.3) (0.17.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter==1.1.1) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter==1.1.1) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter==1.1.1) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter==1.1.1) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter==1.1.1) (7.7.1)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.12/dist-packages (from jupyter==1.1.1) (4.4.10)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.1) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.3.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.3.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.3.2) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.6) (3.2.5)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from plotly==6.3.0) (2.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk==3.9.1) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk==3.9.1) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk==3.9.1) (4.67.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.12/dist-packages (from umap-learn==0.5.9.post2) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn==0.5.9.post2) (0.5.13)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.20.0) (0.45.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.2->umap-learn==0.5.9.post2) (0.43.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (3.1.3)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter==1.1.1) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter==1.1.1) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter==1.1.1) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter==1.1.1) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter==1.1.1) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter==1.1.1) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter==1.1.1) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter==1.1.1) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter==1.1.1) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter==1.1.1) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter==1.1.1) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter==1.1.1) (3.0.15)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter==1.1.1) (5.9.1)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter==1.1.1) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter==1.1.1) (2.19.2)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter==1.1.1) (2.0.5)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter==1.1.1) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter==1.1.1) (3.1.6)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter==1.1.1) (2.3.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter==1.1.1) (2.14.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter==1.1.1) (2.28.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter==1.1.1) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter==1.1.1) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter==1.1.1) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter==1.1.1) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter==1.1.1) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter==1.1.1) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter==1.1.1) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter==1.1.1) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter==1.1.1) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter==1.1.1) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter==1.1.1) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter==1.1.1) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter==1.1.1) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter==1.1.1) (1.3.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras==3.11.3) (4.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1) (0.16.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter==1.1.1) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-console->jupyter==1.1.1) (4.5.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.9.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter==1.1.1) (25.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (0.12.1)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (4.25.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.11.3) (0.1.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.1.1) (2.21.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter==1.1.1) (0.2.14)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.1.1) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.1.1) (2.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.8.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (0.28.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.1.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.1.1) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.1.1) (2.23)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (24.11.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test code for environment setup\n",
        "# import library\n",
        "import dotenv\n",
        "import gensim\n",
        "import tensorflow\n",
        "import tensorflow_hub\n",
        "import keras\n",
        "import jupyter\n",
        "import sklearn\n",
        "import pandas\n",
        "import numpy\n",
        "import matplotlib\n",
        "import plotly\n",
        "import seaborn\n",
        "import nltk\n",
        "import umap\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"gensim: \" + gensim.__version__)\n",
        "print(\"tensorflow: \" + tensorflow.__version__)\n",
        "print(\"keras: \" + keras.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP0POOdZvXwi",
        "outputId": "0e532cfa-63c3-46da-be62-f70201a667cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gensim: 4.3.3\n",
            "tensorflow: 2.20.0\n",
            "keras: 3.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **OPTIONAL: If you want to save your outputs you can send them to your own drive by mounting the drive in the following way (uncomment the lines):**"
      ],
      "metadata": {
        "id": "2By46A7lvl1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Remember to change the directory of your outputs to your folder in the new mounted google drive inside colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "id": "OKBaNNh7vkOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cffc8a-e584-4caa-9c86-7ae0c5313101"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KpYc_FWui7T"
      },
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Data Mining Lab 2 - Phase 1](#toc1_)    \n",
        "  - [Summarized Table of Contents](#toc1_1_)    \n",
        "  - [Before Starting](#toc1_2_)    \n",
        "  - [Introduction](#toc1_3_)    \n",
        "  - [**1. Data Preparation**](#toc1_4_)    \n",
        "  - [**1.1 Load data**](#toc1_5_)    \n",
        "        - [**>>> Exercise 1 (Take home):**](#toc1_5_1_1_1_)    \n",
        "    - [**1.2 Save data**](#toc1_5_2_)    \n",
        "    - [**1.3 Exploratory data analysis (EDA)**](#toc1_5_3_)    \n",
        "  - [**2. Feature engineering**](#toc1_6_)    \n",
        "    - [Using Bag of Words](#toc1_6_1_)    \n",
        "        - [**>>> Exercise 2 (Take home):**](#toc1_6_1_1_1_)    \n",
        "  - [**3. Model**](#toc1_7_)    \n",
        "    - [**3.1 Decision Trees**](#toc1_7_1_)    \n",
        "  - [**4. Results Evaluation**](#toc1_8_)    \n",
        "        - [**>>> Exercise 3 (Take home):**](#toc1_8_1_1_1_)    \n",
        "        - [**>>> Exercise 4 (Take home):**](#toc1_8_1_1_2_)    \n",
        "        - [**>>> Exercise 5 (Take home):**](#toc1_8_1_1_3_)    \n",
        "  - [**5. Other things you can try**](#toc1_9_)    \n",
        "  - [**6. Deep Learning**](#toc1_10_)    \n",
        "    - [**6.1 Prepare data (X, y)**](#toc1_10_1_)    \n",
        "    - [**6.2 Deal with categorical label (y)**](#toc1_10_2_)    \n",
        "    - [**6.3 Build model**](#toc1_10_3_)    \n",
        "    - [**6.4 Train**](#toc1_10_4_)    \n",
        "    - [**6.5 Predict on testing data**](#toc1_10_5_)    \n",
        "        - [**>>> Exercise 6 (Take home):**](#toc1_10_5_1_1_)    \n",
        "    - [Note](#toc1_10_6_)    \n",
        "    - [More Information for your reference](#toc1_10_7_)    \n",
        "  - [**7. Word2Vector**](#toc1_11_)    \n",
        "    - [**7.1 Prepare training corpus**](#toc1_11_1_)    \n",
        "    - [**7.2 Training our model**](#toc1_11_2_)    \n",
        "    - [**7.3 Generating word vector (embeddings)**](#toc1_11_3_)    \n",
        "    - [**7.4 Using a pre-trained w2v model**](#toc1_11_4_)    \n",
        "      - [(1) Download model by yourself](#toc1_11_4_1_)    \n",
        "      - [(2) Using gensim api](#toc1_11_4_2_)    \n",
        "    - [**7.5 king + woman - man = ?**](#toc1_11_5_)    \n",
        "        - [**>>> Exercise 7 (Take home):**](#toc1_11_5_1_1_)    \n",
        "  - [**8. Clustering: k-means**](#toc1_12_)    \n",
        "      - [Basic concept](#toc1_12_1_1_)    \n",
        "  - [**9. High-dimension Visualization: t-SNE and UMAP**](#toc1_13_)    \n",
        "    - [**9.1 Prepare visualizing target**](#toc1_13_1_)    \n",
        "    - [**9.2 Plot using t-SNE and UMAP (2-dimension)**](#toc1_13_2_)    \n",
        "        - [**>>> Exercise 8 (Take home):**](#toc1_13_2_1_1_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuutyCx4YTpX"
      },
      "source": [
        "# <a id='toc1_'></a>[Data Mining Lab 2 - Phase 1](#toc0_)\n",
        "In this lab's phase 1 session we will focus on the use of Neural Word Embeddings\n",
        "\n",
        "## <a id='toc1_1_'></a>[Summarized Table of Contents](#toc0_)\n",
        "- **Phase 1:**\n",
        "1. Data preparation\n",
        "2. Feature engineering\n",
        "3. Model\n",
        "4. Results evaluation\n",
        "5. Other things you could try\n",
        "6. Deep Learning\n",
        "7. Word to Vector\n",
        "8. Clustering\n",
        "9. High-dimension Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XUuDBRcui7V"
      },
      "source": [
        "## <a id='toc1_2_'></a>[Before Starting](#toc0_)\n",
        "\n",
        "**Make sure you have installed all the required libraries and you have the environment ready to run this lab.**\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIpAqCvMYTpX"
      },
      "source": [
        "---\n",
        "## <a id='toc1_3_'></a>[Introduction](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2paPeNbYTpX"
      },
      "source": [
        "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
        "\n",
        "**Task:** Classify text data into 4 different emotions using word embeddings and other deep information retrieval approaches.\n",
        "\n",
        "![pic0.png](https://drive.google.com/uc?export=view&id=1qurztXdx30Wl2vkCZg7KXXJYJXcE6YR_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op_X7pR-YTpX"
      },
      "source": [
        "---\n",
        "## <a id='toc1_4_'></a>[**1. Data Preparation**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID-8I1ELYTpX"
      },
      "source": [
        "Before beggining the lab, please make sure to download the [Google News Dataset](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit) and place it in a folder named \"GoogleNews\" in the same directory as this file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgoEbZzSYTpX"
      },
      "source": [
        "---\n",
        "## <a id='toc1_5_'></a>[**1.1 Load data**](#toc0_)\n",
        "\n",
        "We start by loading the csv files into a single pandas dataframe for training and one for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "anfjcPSSYTpX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "### training data\n",
        "anger_train = pd.read_csv(\"./DM2025-Lab2-Exercise/data/semeval/train/anger-ratings-0to1.train.txt\",\n",
        "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "sadness_train = pd.read_csv(\"./DM2025-Lab2-Exercise/data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "fear_train = pd.read_csv(\"./DM2025-Lab2-Exercise/data/semeval/train/fear-ratings-0to1.train.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "joy_train = pd.read_csv(\"./DM2025-Lab2-Exercise/data/semeval/train/joy-ratings-0to1.train.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "yVc2T5MIYTpX"
      },
      "outputs": [],
      "source": [
        "# combine 4 sub-dataset\n",
        "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Kw8bGMv7YTpX",
        "outputId": "49d7df81-133a-4b34-e514-c6541e526e13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text emotion  intensity\n",
              "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
              "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
              "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
              "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
              "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92fcd6ef-99fc-4096-9ab4-76d7ba20641c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>So my Indian Uber driver just called someone t...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92fcd6ef-99fc-4096-9ab4-76d7ba20641c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92fcd6ef-99fc-4096-9ab4-76d7ba20641c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92fcd6ef-99fc-4096-9ab4-76d7ba20641c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ad4d7b29-4f3d-49b0-b5d4-8cdb2d85b120\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad4d7b29-4f3d-49b0-b5d4-8cdb2d85b120')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ad4d7b29-4f3d-49b0-b5d4-8cdb2d85b120 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 3613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10715,\n        \"min\": 10000,\n        \"max\": 40785,\n        \"num_unique_values\": 3613,\n        \"samples\": [\n          10839,\n          30626,\n          10032\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3565,\n        \"samples\": [\n          \"im literally shaking bc im nervous and bc its fucking cold oh how i love life\",\n          \"Halfway to work and I realize I forgot to put on underwear....It's going to be one of those days! #mombrain #toomuchgoingon #longday #breezy\",\n          \"Round 2  #pcola\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"fear\",\n          \"sadness\",\n          \"anger\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19036776242787684,\n        \"min\": 0.019,\n        \"max\": 0.98,\n        \"num_unique_values\": 403,\n        \"samples\": [\n          0.333,\n          0.673,\n          0.654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "### testing data\n",
        "anger_test = pd.read_csv(\"./DM2025-Lab2-Exercise/data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "sadness_test = pd.read_csv(\"./DM2025-Lab2-Exercise/data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "fear_test = pd.read_csv(\"./DM2025-Lab2-Exercise/data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "joy_test = pd.read_csv(\"./DM2025-Lab2-Exercise/data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
        "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
        "\n",
        "# combine 4 sub-dataset\n",
        "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "HBHwcL8sYTpX"
      },
      "outputs": [],
      "source": [
        "# shuffle dataset\n",
        "train_df = train_df.sample(frac=1)\n",
        "test_df = test_df.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w_cDUwCYTpX",
        "outputId": "6f313150-d76b-474f-95f5-c345cfbae1f6",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training df:  (3613, 4)\n",
            "Shape of Testing df:  (347, 4)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of Training df: \", train_df.shape)\n",
        "print(\"Shape of Testing df: \", test_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "escCgU1zYTpX"
      },
      "source": [
        "---\n",
        "##### <a id='toc1_5_1_1_1_'></a>[**>>> Exercise 1 (Take home):**](#toc0_)\n",
        "Plot word frequency for Top 30 words in both train and test dataset. (Hint: refer to DM lab 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HoXjet3pYTpo"
      },
      "outputs": [],
      "source": [
        "# Answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hr8aKhlYTpo"
      },
      "source": [
        "---\n",
        "### <a id='toc1_5_2_'></a>[**1.2 Save data**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm6GF2VvYTpo"
      },
      "source": [
        "We will save our data in Pickle format. The pickle module implements binary protocols for serializing and de-serializing a Python object structure.   \n",
        "  \n",
        "Some advantages for using pickle structure:  \n",
        "* Because it stores the attribute type, it's more convenient for cross-platform use.  \n",
        "* When your data is huge, it could use less space to store also consume less loading time.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dZzepBdpYTpo"
      },
      "outputs": [],
      "source": [
        "# save to pickle file\n",
        "train_df.to_pickle(\"./DM2025-Lab2-Exercise/data/train_df.pkl\")\n",
        "test_df.to_pickle(\"./DM2025-Lab2-Exercise/data/test_df.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "H5uO-kOUYTpo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load a pickle file\n",
        "train_df = pd.read_pickle(\"./DM2025-Lab2-Exercise/data/train_df.pkl\")\n",
        "test_df = pd.read_pickle(\"./DM2025-Lab2-Exercise/data/test_df.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sLDcQzeYTpo"
      },
      "source": [
        "For more information: https://reurl.cc/0Dzqx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKHpxTzLYTpo"
      },
      "source": [
        "---\n",
        "### <a id='toc1_5_3_'></a>[**1.3 Exploratory data analysis (EDA)**](#toc0_)\n",
        "\n",
        "Again, before getting our hands dirty, we need to explore a little bit and understand the data we're dealing with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "mLnEEliCYTpo",
        "outputId": "071a7b89-895c-41b8-bc5c-a8bb74f18eee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "emotion\n",
              "anger       857\n",
              "fear       1147\n",
              "joy         823\n",
              "sadness     786\n",
              "Name: text, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>1147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>joy</th>\n",
              "      <td>823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sadness</th>\n",
              "      <td>786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# group to find distribution\n",
        "train_df.groupby(['emotion']).count()['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "pcVOe8nYYTpo",
        "outputId": "baab14b4-3f01-4cec-937c-351946cfb5b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# the histogram of the data\n",
        "labels = train_df['emotion'].unique()\n",
        "post_total = len(train_df)\n",
        "df1 = train_df.groupby(['emotion']).count()['text']\n",
        "df1 = df1.apply(lambda x: round(x*100/post_total,3))\n",
        "\n",
        "#plot\n",
        "fig, ax = plt.subplots(figsize=(5,3))\n",
        "plt.bar(df1.index,df1.values)\n",
        "\n",
        "#arrange\n",
        "plt.ylabel('% of instances')\n",
        "plt.xlabel('Emotion')\n",
        "plt.title('Emotion distribution')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_jGcireYTpo"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgHvhTJuYTpo"
      },
      "source": [
        "## <a id='toc1_6_'></a>[**2. Feature engineering**](#toc0_)\n",
        "### <a id='toc1_6_1_'></a>[Using Bag of Words](#toc0_)\n",
        "Using scikit-learn ```CountVectorizer``` perform word frequency and use these as features to train a model.  \n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rbl89LPUYTpo"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Bo8_GP6qYTpo"
      },
      "outputs": [],
      "source": [
        "# build analyzers (bag-of-words)\n",
        "BOW_vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Bz_m0xn7YTpo"
      },
      "outputs": [],
      "source": [
        "# 1. Learn a vocabulary dictionary of all tokens in the raw documents.\n",
        "BOW_vectorizer.fit(train_df['text'])\n",
        "\n",
        "# 2. Transform documents to document-term matrix.\n",
        "train_data_BOW_features = BOW_vectorizer.transform(train_df['text'])\n",
        "test_data_BOW_features = BOW_vectorizer.transform(test_df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cpCUVN8YTpo",
        "outputId": "144e02dd-d955-427a-c84f-7912007faa10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3613x10115 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 51467 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# check the result\n",
        "train_data_BOW_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "irGLsag-YTpo",
        "outputId": "83c9b367-8018-4c65-9116-df186b5fa5cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse._csr.csr_matrix"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>scipy.sparse._csr.csr_matrix</b><br/>def __init__(arg1, shape=None, dtype=None, copy=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/scipy/sparse/_csr.py</a>Compressed Sparse Row matrix.\n",
              "\n",
              "This can be instantiated in several ways:\n",
              "    csr_matrix(D)\n",
              "        where D is a 2-D ndarray\n",
              "\n",
              "    csr_matrix(S)\n",
              "        with another sparse array or matrix S (equivalent to S.tocsr())\n",
              "\n",
              "    csr_matrix((M, N), [dtype])\n",
              "        to construct an empty matrix with shape (M, N)\n",
              "        dtype is optional, defaulting to dtype=&#x27;d&#x27;.\n",
              "\n",
              "    csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
              "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
              "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
              "\n",
              "    csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
              "        is the standard CSR representation where the column indices for\n",
              "        row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
              "        corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
              "        If the shape parameter is not supplied, the matrix dimensions\n",
              "        are inferred from the index arrays.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "dtype : dtype\n",
              "    Data type of the matrix\n",
              "shape : 2-tuple\n",
              "    Shape of the matrix\n",
              "ndim : int\n",
              "    Number of dimensions (this is always 2)\n",
              "nnz\n",
              "size\n",
              "data\n",
              "    CSR format data array of the matrix\n",
              "indices\n",
              "    CSR format index array of the matrix\n",
              "indptr\n",
              "    CSR format index pointer array of the matrix\n",
              "has_sorted_indices\n",
              "has_canonical_format\n",
              "T\n",
              "\n",
              "Notes\n",
              "-----\n",
              "\n",
              "Sparse matrices can be used in arithmetic operations: they support\n",
              "addition, subtraction, multiplication, division, and matrix power.\n",
              "\n",
              "Advantages of the CSR format\n",
              "  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
              "  - efficient row slicing\n",
              "  - fast matrix vector products\n",
              "\n",
              "Disadvantages of the CSR format\n",
              "  - slow column slicing operations (consider CSC)\n",
              "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
              "\n",
              "Canonical Format\n",
              "    - Within each row, indices are sorted by column.\n",
              "    - There are no duplicate entries.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; from scipy.sparse import csr_matrix\n",
              "&gt;&gt;&gt; csr_matrix((3, 4), dtype=np.int8).toarray()\n",
              "array([[0, 0, 0, 0],\n",
              "       [0, 0, 0, 0],\n",
              "       [0, 0, 0, 0]], dtype=int8)\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 0, 1, 2, 2, 2])\n",
              "&gt;&gt;&gt; col = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "&gt;&gt;&gt; indptr = np.array([0, 2, 3, 6])\n",
              "&gt;&gt;&gt; indices = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "Duplicate entries are summed together:\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 1, 2, 0])\n",
              "&gt;&gt;&gt; col = np.array([0, 1, 1, 0])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 4, 8])\n",
              "&gt;&gt;&gt; csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[9, 0, 0],\n",
              "       [0, 2, 0],\n",
              "       [0, 4, 0]])\n",
              "\n",
              "As an example of how to construct a CSR matrix incrementally,\n",
              "the following snippet builds a term-document matrix from texts:\n",
              "\n",
              "&gt;&gt;&gt; docs = [[&quot;hello&quot;, &quot;world&quot;, &quot;hello&quot;], [&quot;goodbye&quot;, &quot;cruel&quot;, &quot;world&quot;]]\n",
              "&gt;&gt;&gt; indptr = [0]\n",
              "&gt;&gt;&gt; indices = []\n",
              "&gt;&gt;&gt; data = []\n",
              "&gt;&gt;&gt; vocabulary = {}\n",
              "&gt;&gt;&gt; for d in docs:\n",
              "...     for term in d:\n",
              "...         index = vocabulary.setdefault(term, len(vocabulary))\n",
              "...         indices.append(index)\n",
              "...         data.append(1)\n",
              "...     indptr.append(len(indices))\n",
              "...\n",
              "&gt;&gt;&gt; csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
              "array([[2, 1, 0, 0],\n",
              "       [0, 1, 1, 1]])</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 370);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "type(train_data_BOW_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqbR8KWNYTpo",
        "outputId": "854ac03a-2667-4c67-b55c-476cfac5a216",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# add .toarray() to show\n",
        "train_data_BOW_features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL0xkGyGYTpo",
        "outputId": "f3f9cdfa-911d-43c5-aa9c-285f13b1f2e2",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3613, 10115)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# check the dimension\n",
        "train_data_BOW_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyRaxyBZYTpo",
        "outputId": "185166a8-3f7d-4cf9-c0d4-d78ca5a6dad5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['2k17', '2much', '2nd', '30', '300', '301', '30am', '30pm', '30s',\n",
              "       '31'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# observe some feature names\n",
        "feature_names = BOW_vectorizer.get_feature_names_out()\n",
        "feature_names[100:110]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roSfgQKaYTpo"
      },
      "source": [
        "The embedding is done. We can technically feed this into our model. However, depending on the embedding technique you use and your model, your accuracy might not be as high, because:\n",
        "\n",
        "* curse of dimensionality  (we have 10,115 dimension now)\n",
        "* some important features are ignored (for example, some models using emoticons yeld better performance than counterparts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx4YPbrdYTpo",
        "outputId": "9b60bfdf-b03c-4a4a-b78f-573781b26813"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "\"\" in feature_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MFzyA95YTpo"
      },
      "source": [
        "Let's try using another tokenizer below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SttodxACYTpo",
        "outputId": "84b5eb7b-9b12-4072-dc0b-12fd90968aec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3613, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "# build analyzers (bag-of-words)\n",
        "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize)\n",
        "\n",
        "# apply analyzer to training data\n",
        "BOW_500.fit(train_df['text'])\n",
        "\n",
        "train_data_BOW_features_500 = BOW_500.transform(train_df['text'])\n",
        "\n",
        "## check dimension\n",
        "train_data_BOW_features_500.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPi42W0pYTpo",
        "outputId": "be7ac568-d650-48d8-fb77-c74bef5381ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 7, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "train_data_BOW_features_500.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCgAnTOfYTpo",
        "outputId": "78c2e2a0-455d-40f9-b6cf-e859bc279023"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['change', 'cheer', 'cheerful', 'cheering', 'cheery', 'come',\n",
              "       'comes', 'could', 'country', 'cry'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# observe some feature names\n",
        "feature_names_500 = BOW_500.get_feature_names_out()\n",
        "feature_names_500[100:110]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubgedNi4YTpo",
        "outputId": "fbe39106-d6e2-4298-cae8-c47bab216536"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "\"\" in feature_names_500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj6TV4ngYTpo"
      },
      "source": [
        "---\n",
        "##### <a id='toc1_6_1_1_1_'></a>[**>>> Exercise 2 (Take home):**](#toc0_)\n",
        "Generate an embedding using the TF-IDF vectorizer instead of th BOW one with 1000 features and show the feature names for features [100:110]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BOjVbgmxYTpo"
      },
      "outputs": [],
      "source": [
        "# Answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0BvbNAVYTpo"
      },
      "source": [
        "---\n",
        "## <a id='toc1_7_'></a>[**3. Model**](#toc0_)\n",
        "### <a id='toc1_7_1_'></a>[**3.1 Decision Trees**](#toc0_)\n",
        "Using scikit-learn ```DecisionTreeClassifier``` performs word frequency and uses these as features to train a model.  \n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD0rMWKgYTpo",
        "outputId": "7c5db15c-3aba-46af-c2cf-c1ce8739825d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape:  (3613, 500)\n",
            "y_train.shape:  (3613,)\n",
            "X_test.shape:  (347, 500)\n",
            "y_test.shape:  (347,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# for a classificaiton problem, you need to provide both training & testing data\n",
        "X_train = BOW_500.transform(train_df['text'])\n",
        "y_train = train_df['emotion']\n",
        "\n",
        "X_test = BOW_500.transform(test_df['text'])\n",
        "y_test = test_df['emotion']\n",
        "\n",
        "## take a look at data dimension is a good habit  :)\n",
        "print('X_train.shape: ', X_train.shape)\n",
        "print('y_train.shape: ', y_train.shape)\n",
        "print('X_test.shape: ', X_test.shape)\n",
        "print('y_test.shape: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDuvLf7TYTpo",
        "outputId": "b3c309e5-7d04-4964-903c-540bbe88396f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['fear', 'joy', 'sadness', 'fear', 'fear', 'fear', 'fear', 'fear',\n",
              "       'joy', 'sadness'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "## build DecisionTree model\n",
        "DT_model = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "## training!\n",
        "DT_model = DT_model.fit(X_train, y_train)\n",
        "\n",
        "## predict!\n",
        "y_train_pred = DT_model.predict(X_train)\n",
        "y_test_pred = DT_model.predict(X_test)\n",
        "\n",
        "## so we get the pred result\n",
        "y_test_pred[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBNmBT50YTpo"
      },
      "source": [
        "---\n",
        "## <a id='toc1_8_'></a>[**4. Results Evaluation**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gQU_PbhYTpo"
      },
      "source": [
        "Now we will check the results of our model's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9yx3tv-YTpo",
        "outputId": "f203a4e8-17cf-4a9f-8d86-6d446f95a6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy: 0.99\n",
            "testing accuracy: 0.66\n"
          ]
        }
      ],
      "source": [
        "## accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
        "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
        "\n",
        "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
        "print('testing accuracy: {}'.format(round(acc_test, 2)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wkOqjqiYTpo",
        "outputId": "306d3b44-869e-4a4b-9802-e4b1fca9a95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.62      0.71      0.67        84\n",
            "        fear       0.67      0.63      0.65       110\n",
            "         joy       0.74      0.67      0.70        79\n",
            "     sadness       0.62      0.64      0.63        74\n",
            "\n",
            "    accuracy                           0.66       347\n",
            "   macro avg       0.66      0.66      0.66       347\n",
            "weighted avg       0.66      0.66      0.66       347\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## precision, recall, f1-score,\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6mhrmKHYTpo",
        "outputId": "b81b4569-3db2-453d-a0dc-d40d6c0d0c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[60 11  7  6]\n",
            " [20 69  7 14]\n",
            " [ 6 11 53  9]\n",
            " [10 12  5 47]]\n"
          ]
        }
      ],
      "source": [
        "## check by confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-TcX8NA5YTpo"
      },
      "outputs": [],
      "source": [
        "# Funciton for visualizing confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
        "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
        "    \"\"\"\n",
        "    This function is modified from:\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \"\"\"\n",
        "    classes.sort()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels = classes,\n",
        "           yticklabels = classes,\n",
        "           title = title,\n",
        "           xlabel = 'Predicted label',\n",
        "           ylabel = 'True label')\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    ylim_top = len(classes) - 0.5\n",
        "    plt.ylim([ylim_top, -.5])\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "1nBVOUpDYTpo",
        "outputId": "dffb4c87-d584-4ee4-a3ab-6201fcd9285c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot your confusion matrix\n",
        "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
        "plot_confusion_matrix(cm, classes=my_tags, title='Confusion matrix')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l743vmwgYTpo"
      },
      "source": [
        "---\n",
        "##### <a id='toc1_8_1_1_1_'></a>[**>>> Exercise 3 (Take home):**](#toc0_)\n",
        "Can you interpret the results above? What do they mean?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8pYICOxsYTpo"
      },
      "outputs": [],
      "source": [
        "# Answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaHpgl87YTpo"
      },
      "source": [
        "---\n",
        "##### <a id='toc1_8_1_1_2_'></a>[**>>> Exercise 4 (Take home):**](#toc0_)\n",
        "Build a model using a ```Naive Bayes``` model and train it. What are the testing results?\n",
        "\n",
        "*Reference*: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZPvaHzpXYTpo"
      },
      "outputs": [],
      "source": [
        "# Answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv2DqWQSYTpo"
      },
      "source": [
        "---\n",
        "##### <a id='toc1_8_1_1_3_'></a>[**>>> Exercise 5 (Take home):**](#toc0_)\n",
        "\n",
        "How do the results from the Naive Bayes model and the Decision Tree model compare? How do you interpret these differences? Use the theoretical background covered in class to try and explain these differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ALN_jHdlYTpo"
      },
      "outputs": [],
      "source": [
        "# Answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehlJ60lhYTpo"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79F_DaW-YTpo"
      },
      "source": [
        "## <a id='toc1_9_'></a>[**5. Other things you can try**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oeqpRu6YTpo"
      },
      "source": [
        "Thus, there are several things you can try that will affect your results. In order to yield better results, you can experiment by:\n",
        "- Trying different features (Feature engineering)e.g Word2Vec, PCA, LDA, FastText, Clustering\n",
        "- Trying different models\n",
        "- Analyzing your results and interpret them to improve your feature engineering/model building process\n",
        "- Iterate through the steps above until finding a satisfying result\n",
        "\n",
        "Remember that you should also consider the task at hand and the model you'll feed the data to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiGUSmPLYTpo"
      },
      "source": [
        "---\n",
        "## <a id='toc1_10_'></a>[**6. Deep Learning**](#toc0_)\n",
        "\n",
        "We use [Keras](https://keras.io/) to be our deep learning framework, and follow the [Model (functional API)](https://keras.io/models/model/) to build a Deep Neural Network (DNN) model. Keras runs with Tensorflow in the backend. It's a nice abstraction to start working with NN models.\n",
        "\n",
        "Because Deep Learning is a 1-semester course, we can't talk about each detail about it in the lab session. Here, we only provide a simple template about how to build & run a DL model successfully. You can follow this template to design your model.\n",
        "\n",
        "We will begin by building a fully connected network, which looks like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nB0BTq2YTpo"
      },
      "source": [
        "![pic1.png](https://drive.google.com/uc?export=view&id=1DKd43x7RNHTa2gn_HUV2SRNJ7MhV0dKh)\n",
        "\n",
        "(source: https://github.com/drewnoff/spark-notebook-ml-labs/tree/master/labs/DLFramework)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EtVRGhNYTpo"
      },
      "source": [
        "---\n",
        "### <a id='toc1_10_1_'></a>[**6.1 Prepare data (X, y)**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mIdg2D6YTpo",
        "outputId": "fd6f46d4-a607-4785-dd64-5b0265890de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape:  (3613, 500)\n",
            "y_train.shape:  (3613,)\n",
            "X_test.shape:  (347, 500)\n",
            "y_test.shape:  (347,)\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "\n",
        "# standardize name (X, y)\n",
        "X_train = BOW_500.transform(train_df['text'])\n",
        "y_train = train_df['emotion']\n",
        "\n",
        "X_test = BOW_500.transform(test_df['text'])\n",
        "y_test = test_df['emotion']\n",
        "\n",
        "## check dimension is a good habbit\n",
        "print('X_train.shape: ', X_train.shape)\n",
        "print('y_train.shape: ', y_train.shape)\n",
        "print('X_test.shape: ', X_test.shape)\n",
        "print('y_test.shape: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9hLJNJPUui7f"
      },
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFUlu8s4ui7f",
        "outputId": "ee8ce7d3-caef-4cea-fef8-e8e270aca58e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<347x500 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 4103 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "BOW_500.transform(test_df['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBZZedZ2YTpo"
      },
      "source": [
        "---\n",
        "### <a id='toc1_10_2_'></a>[**6.2 Deal with categorical label (y)**](#toc0_)\n",
        "\n",
        "Rather than put your label `train_df['emotion']` directly into a model, we have to process these categorical (or say nominal) label by ourselves.\n",
        "\n",
        "Here, we use the basic method [one-hot encoding](https://en.wikipedia.org/wiki/One-hot) to transform our categorical  labels to numerical ones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAlHeAoPui7f",
        "outputId": "ab6dac45-11e4-4add-f52a-9665ff5435a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check label:  ['anger' 'fear' 'joy' 'sadness']\n",
            "\n",
            "## Before convert\n",
            "y_train[0:4]:\n",
            " 3148    sadness\n",
            "3379    sadness\n",
            "2378        joy\n",
            "3070    sadness\n",
            "Name: emotion, dtype: object\n",
            "\n",
            "y_train.shape:  (3613,)\n",
            "y_test.shape:  (347,)\n"
          ]
        }
      ],
      "source": [
        "# deal with label (string -> one-hot)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "\n",
        "print('check label: ', label_encoder.classes_)\n",
        "print('\\n## Before convert')\n",
        "print('y_train[0:4]:\\n', y_train[0:4])\n",
        "print('\\ny_train.shape: ', y_train.shape)\n",
        "print('y_test.shape: ', y_test.shape)\n",
        "\n",
        "def label_encode(le, labels):\n",
        "    enc = le.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def label_decode(le, one_hot_label):\n",
        "    dec = np.argmax(one_hot_label, axis=1)\n",
        "    return le.inverse_transform(dec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU95MCsSYTpo",
        "outputId": "758c41f4-faf9-4288-99b8-916e353ac162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "## After convert\n",
            "y_train[0:4]:\n",
            " [[0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n",
            "\n",
            "y_train.shape:  (3613, 4)\n",
            "y_test.shape:  (347, 4)\n"
          ]
        }
      ],
      "source": [
        "y_train = label_encode(label_encoder, y_train)\n",
        "y_test = label_encode(label_encoder, y_test)\n",
        "\n",
        "print('\\n\\n## After convert')\n",
        "print('y_train[0:4]:\\n', y_train[0:4])\n",
        "print('\\ny_train.shape: ', y_train.shape)\n",
        "print('y_test.shape: ', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4bqEcMbYTpo"
      },
      "source": [
        "---\n",
        "### <a id='toc1_10_3_'></a>[**6.3 Build model**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sA7cx-oYTpo",
        "outputId": "de41243f-c9e7-4084-b0b2-c7ffab75a1c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_shape:  500\n",
            "output_shape:  4\n"
          ]
        }
      ],
      "source": [
        "# I/O check\n",
        "input_shape = X_train.shape[1]\n",
        "print('input_shape: ', input_shape)\n",
        "\n",
        "output_shape = len(label_encoder.classes_)\n",
        "print('output_shape: ', output_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c-uWuloYTpo"
      },
      "source": [
        "![pic2.png](https://drive.google.com/uc?export=view&id=1F_RmXNBo3uUPyopFmYne61s-H4ecl-iz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "jTeBWTvgYTpo",
        "outputId": "7bb11de1-2164-4882-b5b5-3b0e1eb02731"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m32,064\u001b[0m \n",
              "\n",
              " re_lu (\u001b[38;5;33mReLU\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                      \u001b[38;5;34m4,160\u001b[0m \n",
              "\n",
              " re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                         \u001b[38;5;34m260\u001b[0m \n",
              "\n",
              " softmax (\u001b[38;5;33mSoftmax\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,064</span> \n",
              "\n",
              " re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> \n",
              "\n",
              " re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> \n",
              "\n",
              " softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,484\u001b[0m (142.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,484</span> (142.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,484\u001b[0m (142.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,484</span> (142.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import ReLU, Softmax\n",
        "\n",
        "# input layer\n",
        "model_input = Input(shape=(input_shape, ))  # 500\n",
        "X = model_input\n",
        "\n",
        "# 1st hidden layer\n",
        "X_W1 = Dense(units=64)(X)  # 64\n",
        "H1 = ReLU()(X_W1)\n",
        "\n",
        "# 2nd hidden layer\n",
        "H1_W2 = Dense(units=64)(H1)  # 64\n",
        "H2 = ReLU()(H1_W2)\n",
        "\n",
        "# output layer\n",
        "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
        "H3 = Softmax()(H2_W3)\n",
        "\n",
        "model_output = H3\n",
        "\n",
        "# create model\n",
        "model = Model(inputs=[model_input], outputs=[model_output])\n",
        "\n",
        "# loss function & optimizer\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# show model construction\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmTSDO2pYTpo"
      },
      "source": [
        "---\n",
        "### <a id='toc1_10_4_'></a>[**6.4 Train**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Kl374LYqYTpo",
        "outputId": "88a2197b-04d5-4d7c-bde3-c5293fa15176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 455ms/step - accuracy: 0.3670 - loss: 1.3268 - val_accuracy: 0.4207 - val_loss: 1.2762\n",
            "Epoch 2/25\n",
            "\u001b[1m  8/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 161ms/step - accuracy: 0.5318 - loss: 1.2302 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-153060367.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# training!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m     11\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mbegin_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "csv_logger = CSVLogger('./DM2025-Lab2-Exercise/logs/training_log.csv')\n",
        "\n",
        "# training setting\n",
        "epochs = 25\n",
        "batch_size = 32\n",
        "\n",
        "# training!\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[csv_logger],\n",
        "                    validation_data = (X_test, y_test))\n",
        "print('training finish')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip8RYsvSYTpo"
      },
      "source": [
        "---\n",
        "### <a id='toc1_10_5_'></a>[**6.5 Predict on testing data**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdnLuBYBYTpo"
      },
      "outputs": [],
      "source": [
        "## predict\n",
        "pred_result = model.predict(X_test, batch_size=128)\n",
        "pred_result[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSaXGEX-YTpo"
      },
      "outputs": [],
      "source": [
        "pred_result = label_decode(label_encoder, pred_result)\n",
        "pred_result[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRRHye9KYTp5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), pred_result), 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks2Q0aMsYTp5"
      },
      "outputs": [],
      "source": [
        "#Let's take a look at the training log\n",
        "training_log = pd.DataFrame()\n",
        "training_log = pd.read_csv(\"./DM2025-Lab2-Exercise/logs/training_log.csv\")\n",
        "training_log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoYqY0-tYTp5"
      },
      "source": [
        "---\n",
        "##### <a id='toc1_10_5_1_1_'></a>[**>>> Exercise 6 (Take home):**](#toc0_)\n",
        "\n",
        "Plot the Training and Validation Accuracy and Loss (different plots), just like the images below.(Note: the pictures below are an example from a different model). How to interpret the graphs you got? How are they related to the concept of overfitting/underfitting covered in class?\n",
        "\n",
        "![pic3.png](https://drive.google.com/uc?export=view&id=1cYxbZ-72ZJucyUdOsRUEodH203ldZScM)  ![pic4.png](https://drive.google.com/uc?export=view&id=1LybXXqULWkB7IGO3X5g8rLYFx7lhSoms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlhstCrlYTp5"
      },
      "outputs": [],
      "source": [
        "# Answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYabzgSGYTp5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e5eiVLOYTp5"
      },
      "source": [
        "### <a id='toc1_10_6_'></a>[Note](#toc0_)\n",
        "\n",
        "If you don't have a GPU (level is higher than GTX 1060) or you are not good at setting lots of things about computer, we recommend you to use the [kaggle kernel](https://www.kaggle.com/kernels) to do deep learning model training. They have already installed all the librarys and provided free GPU for you to use.\n",
        "\n",
        "Note however that you will only be able to run a kernel for 6 hours. After 6 hours of inactivity, your Kaggle kernel will shut down (meaning if your model takes more than 6 hours to train, you can't train it at once).\n",
        "\n",
        "\n",
        "### <a id='toc1_10_7_'></a>[More Information for your reference](#toc0_)\n",
        "\n",
        "* Keras document: https://keras.io/\n",
        "* Keras GitHub example: https://github.com/keras-team/keras/tree/master/examples\n",
        "* CS229: Machine Learning: http://cs229.stanford.edu/syllabus.html\n",
        "* Deep Learning cheatsheet: https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning\n",
        "* If you want to try TensorFlow or PyTorch: https://pytorch.org/tutorials/\n",
        "https://www.tensorflow.org/tutorials/quickstart/beginner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IESBq48MYTp5"
      },
      "source": [
        "---\n",
        "## <a id='toc1_11_'></a>[**7. Word2Vector**](#toc0_)\n",
        "\n",
        "We will introduce how to use `gensim` to train your word2vec model and how to load a pre-trained model.\n",
        "\n",
        "https://radimrehurek.com/gensim/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRSDMhQ5YTp5"
      },
      "source": [
        "---\n",
        "### <a id='toc1_11_1_'></a>[**7.1 Prepare training corpus**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aBYrovJYTp5"
      },
      "outputs": [],
      "source": [
        "## check library\n",
        "import gensim\n",
        "\n",
        "## ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# # if you want to see the training messages, you can use it\n",
        "# import logging\n",
        "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "## the input type\n",
        "train_df['text_tokenized'] = train_df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
        "train_df[['id', 'text', 'text_tokenized']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okFIEcmnYTp5"
      },
      "outputs": [],
      "source": [
        "## create the training corpus\n",
        "training_corpus = train_df['text_tokenized'].values\n",
        "training_corpus[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOgAriPRYTp5"
      },
      "source": [
        "---\n",
        "### <a id='toc1_11_2_'></a>[**7.2 Training our model**](#toc0_)\n",
        "\n",
        "You can try to train your own model. More details: https://radimrehurek.com/gensim/models/word2vec.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72ZA54IDYTp5",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "## setting\n",
        "vector_dim = 100\n",
        "window_size = 5\n",
        "min_count = 1\n",
        "training_epochs = 20\n",
        "\n",
        "## model\n",
        "word2vec_model = Word2Vec(sentences=training_corpus,\n",
        "                          vector_size=vector_dim, window=window_size,\n",
        "                          min_count=min_count, epochs=training_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob0Molb3YTp5"
      },
      "source": [
        "![Imgur](https://i.imgur.com/Fca3MCs.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0jjvjN5YTp5"
      },
      "source": [
        "---\n",
        "### <a id='toc1_11_3_'></a>[**7.3 Generating word vector (embeddings)**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ejofZfCYTp5"
      },
      "outputs": [],
      "source": [
        "# get the corresponding vector of a word\n",
        "word_vec = word2vec_model.wv['happy']\n",
        "word_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dUSkCscYTp5"
      },
      "outputs": [],
      "source": [
        "# Get the most similar words\n",
        "word = 'happy'\n",
        "topn = 10\n",
        "word2vec_model.wv.most_similar(word, topn=topn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuQvZVJvYTp5"
      },
      "source": [
        "---\n",
        "### <a id='toc1_11_4_'></a>[**7.4 Using a pre-trained w2v model**](#toc0_)\n",
        "\n",
        "Instead of training your own model ,you can use a model that has already been trained. Here, we see 2 ways of doing that:\n",
        "\n",
        "\n",
        "#### <a id='toc1_11_4_1_'></a>[(1) Download model by yourself](#toc0_)\n",
        "\n",
        "source: [GoogleNews-vectors-negative300](https://code.google.com/archive/p/word2vec/)\n",
        "\n",
        "more details: https://radimrehurek.com/gensim/models/keyedvectors.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdH9E9auYTp5"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "## Note: this model is huge, this will take some time ...\n",
        "model_path = f\"{google_news_vectors_path}/GoogleNews-vectors-negative300.bin\"\n",
        "w2v_google_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
        "print('load ok')\n",
        "\n",
        "w2v_google_model.most_similar('happy', topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdQ9ul0eYTp5"
      },
      "source": [
        "#### <a id='toc1_11_4_2_'></a>[(2) Using gensim api](#toc0_)\n",
        "\n",
        "Other pretrained models are available here: https://github.com/RaRe-Technologies/gensim-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIxHpNB6YTp5"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "## If you see `SSL: CERTIFICATE_VERIFY_FAILED` error, use this:\n",
        "import ssl\n",
        "import urllib.request\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "glove_twitter_25_model = api.load(\"glove-twitter-25\")\n",
        "print('load ok')\n",
        "\n",
        "glove_twitter_25_model.most_similar('happy', topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCNDNqeXYTp5"
      },
      "source": [
        "---\n",
        "### <a id='toc1_11_5_'></a>[**7.5 king + woman - man = ?**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GtCRr_7YTp5"
      },
      "source": [
        "Let's run one of the most famous examples for Word2Vec and compute the similarity between these 3 words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zew7m_kIYTp5"
      },
      "outputs": [],
      "source": [
        "w2v_google_model.most_similar(positive=['king', 'woman'], negative=['man'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3RQVnBOYTp5"
      },
      "source": [
        "---\n",
        "##### <a id='toc1_11_5_1_1_'></a>[**>>> Exercise 7 (Take home):**](#toc0_)\n",
        "\n",
        "Now, we have the word vectors, but our input data is a sequence of words (or say sentence).\n",
        "How can we utilize these \"word\" vectors to represent the sentence data and train our model?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBwRT93DYTp5"
      },
      "outputs": [],
      "source": [
        "# Answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrK7O1KDYTp5"
      },
      "source": [
        "---\n",
        "## <a id='toc1_12_'></a>[**8. Clustering: k-means**](#toc0_)\n",
        "\n",
        "Here we introduce how to use `sklearn` to do the basic **unsupervised learning** approach, k-means.    \n",
        "\n",
        "more details: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr8_IxwBYTp5"
      },
      "source": [
        "#### <a id='toc1_12_1_1_'></a>[Basic concept](#toc0_)\n",
        "\n",
        "![pic5.png](https://drive.google.com/uc?export=view&id=1YaPsXWrr7sQFHelMyiNuERs2lG1tZZ54)\n",
        "\n",
        "(img source: https://towardsdatascience.com/k-means-clustering-identifying-f-r-i-e-n-d-s-in-the-world-of-strangers-695537505d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6heUPVwWYTp5"
      },
      "outputs": [],
      "source": [
        "# clustering target\n",
        "target_list = ['happy', 'fear', 'angry', 'car', 'teacher', 'computer']\n",
        "print('target words: ', target_list)\n",
        "\n",
        "# convert to word vector\n",
        "X = [word2vec_model.wv[word] for word in target_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9t_sJrvYTp5"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# we have to decide how many cluster (k) we want\n",
        "k = 2\n",
        "\n",
        "# k-means model\n",
        "kmeans_model = KMeans(n_clusters=k)\n",
        "kmeans_model.fit(X)\n",
        "\n",
        "# cluster result\n",
        "cluster_result = kmeans_model.labels_\n",
        "\n",
        "# show\n",
        "for i in range(len(target_list)):\n",
        "    print('word: {} \\t cluster: {}'.format(target_list[i], cluster_result[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcDTL7kRYTp5"
      },
      "source": [
        "![pic6.png](https://drive.google.com/uc?export=view&id=1loQX4BJI3MlcNmlpjVvqqNTLQSOmxfC4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIMFax_uYTp5"
      },
      "outputs": [],
      "source": [
        "#check cluster membership\n",
        "word = 'student'\n",
        "word_vec = word2vec_model.wv[word]\n",
        "kmeans_model.predict([word_vec])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIDuLDOlYTp5"
      },
      "outputs": [],
      "source": [
        "#check cluster membership\n",
        "word = 'sad'\n",
        "word_vec = word2vec_model.wv[word]\n",
        "kmeans_model.predict([word_vec])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZOEGH3GYTp5"
      },
      "source": [
        "---\n",
        "## <a id='toc1_13_'></a>[**9. High-dimension Visualization: t-SNE and UMAP**](#toc0_)\n",
        "\n",
        "No matter if you use the Bag-of-words, TF-IDF, or Word2Vec, it's very hard to see the embedding result, because the dimension is larger than 3.  \n",
        "\n",
        "In Lab 1, we already talked about PCA, t-SNE and UMAP. We can use PCA to reduce the dimension of our data, then visualize it. However, if you dig deeper into the result, you'd find it is insufficient.\n",
        "\n",
        "Our aim will be to create a visualization similar to the one below with t-SNE:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-JR-rqyYTp5"
      },
      "source": [
        "![pic7.png](https://drive.google.com/uc?export=view&id=1YgtPqQJysWiWKCOvGVjpA07gwgqap3a6)\n",
        "\n",
        "source: https://www.fabian-keller.de/research/high-dimensional-data-visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKnz8k81ui7j"
      },
      "source": [
        "And also like this for UMAP:\n",
        "\n",
        "![pic9.png](https://drive.google.com/uc?export=view&id=1NQsoRSWGYAya0dyDefPXYy7l7Ag6a5UT)\n",
        "\n",
        "source: https://umap-learn.readthedocs.io/en/latest/auto_examples/plot_mnist_example.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmdbJbjxYTp5"
      },
      "source": [
        "t-SNE and UMAP reference:  \n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
        "https://umap-learn.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU8eeDnGYTp5"
      },
      "source": [
        "---\n",
        "### <a id='toc1_13_1_'></a>[**9.1 Prepare visualizing target**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9IHcP3VYTp5"
      },
      "source": [
        "Let's prepare data lists like:\n",
        "- happy words\n",
        "- angry words\n",
        "- data words\n",
        "- mining words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9il5L7pYTp5"
      },
      "outputs": [],
      "source": [
        "word_list = ['happy', 'angry', 'data', 'mining']\n",
        "\n",
        "topn = 5\n",
        "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]\n",
        "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]\n",
        "data_words = ['data'] + [word_ for word_, sim_ in w2v_google_model.most_similar('data', topn=topn)]\n",
        "mining_words = ['mining'] + [word_ for word_, sim_ in w2v_google_model.most_similar('mining', topn=topn)]\n",
        "\n",
        "print('happy_words: ', happy_words)\n",
        "print('angry_words: ', angry_words)\n",
        "print('data_words: ', data_words)\n",
        "print('mining_words: ', mining_words)\n",
        "\n",
        "target_words = happy_words + angry_words + data_words + mining_words\n",
        "print('\\ntarget words: ')\n",
        "print(target_words)\n",
        "\n",
        "print('\\ncolor list:')\n",
        "cn = topn + 1\n",
        "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
        "print(color)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKa5LRxbYTp5"
      },
      "source": [
        "---\n",
        "### <a id='toc1_13_2_'></a>[**9.2 Plot using t-SNE and UMAP (2-dimension)**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJlljN2gYTp5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "## w2v model\n",
        "model = w2v_google_model\n",
        "\n",
        "## prepare training word vectors\n",
        "size = 200\n",
        "target_size = len(target_words)\n",
        "all_word = list(model.index_to_key)\n",
        "word_train = target_words + all_word[:size]\n",
        "X_train = model[word_train]\n",
        "\n",
        "## t-SNE model\n",
        "tsne = TSNE(n_components=2, metric='cosine', random_state=28)\n",
        "\n",
        "## training\n",
        "X_tsne = tsne.fit_transform(X_train)\n",
        "\n",
        "## plot the result\n",
        "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
        "plt.scatter(X_tsne[:target_size, 0], X_tsne[:target_size, 1], c=color)\n",
        "for label, x, y in zip(target_words, X_tsne[:target_size, 0], X_tsne[:target_size, 1]):\n",
        "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNHUnNl-ui7k"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import umap.umap_ as umap\n",
        "\n",
        "## w2v model\n",
        "model = w2v_google_model\n",
        "\n",
        "## prepare training word vectors\n",
        "size = 200\n",
        "target_size = len(target_words)\n",
        "all_word = list(model.index_to_key)\n",
        "word_train = target_words + all_word[:size]\n",
        "X_train = model[word_train]\n",
        "\n",
        "## UMAP model\n",
        "umap_model = umap.UMAP(n_components=2, metric='cosine', random_state=28)\n",
        "\n",
        "## training\n",
        "X_umap = umap_model.fit_transform(X_train)\n",
        "\n",
        "## plot the result\n",
        "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
        "plt.scatter(X_umap[:target_size, 0], X_umap[:target_size, 1], c=color)\n",
        "for label, x, y in zip(target_words, X_umap[:target_size, 0], X_umap[:target_size, 1]):\n",
        "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PL61rqYYTp5"
      },
      "source": [
        "---\n",
        "##### <a id='toc1_13_2_1_1_'></a>[**>>> Exercise 8 (Take home):**](#toc0_)\n",
        "\n",
        "Generate a t-SNE and UMAP visualization to show the 15 words most related to the words \"angry\", \"happy\", \"sad\", \"fear\" (60 words total). Compare the differences between both graphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvh7ymeNYTp5"
      },
      "outputs": [],
      "source": [
        "# Answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fF1woa8YTp5"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4e5eiVLOYTp5"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 594.85,
      "position": {
        "height": "40px",
        "left": "723px",
        "right": "20px",
        "top": "80px",
        "width": "250px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "none",
      "window_display": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}